# Linear Regression Overview

Linear regression is a fundamental technique in machine learning used to model the relationship between dependent and independent variables. It is widely used for predictive modeling, trend analysis, and forecasting.

---

## Types of Linear Regression

### 1. Simple Linear Regression
- Focuses on modeling the relationship between **one independent variable** and a **dependent variable**.
- Example: Predicting house prices based on square footage.

### 2. Multiple Linear Regression
- Extends simple linear regression to include **two or more independent variables**.
- Example: Predicting a car's fuel efficiency based on its engine size, weight, and model year.

### 3. Polynomial Regression
- A variation of linear regression where the relationship between variables is modeled as a **non-linear polynomial function**.
- Useful when the data does not follow a straight-line pattern but exhibits curves.

### 4. Ridge Regression
- A type of linear regression that includes a **regularization term** to reduce overfitting.
- It shrinks coefficients toward zero, making the model more robust.

### 5. Lasso Regression
- Similar to Ridge Regression but performs **feature selection** by shrinking some coefficients to exactly zero.
- Helps identify the most significant features in the model.

### 6. Elastic Net Regression
- Combines the properties of Ridge and Lasso Regression.
- Useful when there are highly correlated independent variables.

---

## Applications
- Predicting trends (e.g., sales, stock prices).
- Estimating relationships (e.g., temperature vs. electricity demand).
- Identifying key factors affecting outcomes.

---

F
